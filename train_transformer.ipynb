{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_transformer.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1puB1lI7uRTLIXQCOFKwj1ANhJw4HM6Er","authorship_tag":"ABX9TyO5/2CSPBWc71Tco3MAQALR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"8836bb2b6acc427ebb184f0bb56e610f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_970e2f61c5c7482b806f87bb176b9c95","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9b67c58409b14e14a1def0307c65e5cc","IPY_MODEL_2e4bfcf2398e4363a1a0c0c649a71de7"]}},"970e2f61c5c7482b806f87bb176b9c95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9b67c58409b14e14a1def0307c65e5cc":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4689346d8cef48629fce05753d0925eb","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_171f64430e624f76849b358ccc995f3d"}},"2e4bfcf2398e4363a1a0c0c649a71de7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4edde0098b9d401ba066bf520e0f4ee3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 35/? [14:37&lt;00:00, 25.07s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_42261fa4c1184f2fb184e9e1bb81a903"}},"4689346d8cef48629fce05753d0925eb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"171f64430e624f76849b358ccc995f3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4edde0098b9d401ba066bf520e0f4ee3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"42261fa4c1184f2fb184e9e1bb81a903":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6a4a078904c94ce79a51213166688c9f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a65149548a084913b53750ddc00da1a6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6c8556bdaa93487a848bf08cef6e1178","IPY_MODEL_376e4649743b400fa36da2bfae2327fd"]}},"a65149548a084913b53750ddc00da1a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6c8556bdaa93487a848bf08cef6e1178":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c0d60302944744fab6708d9df2549a8b","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6b04510fe3c440de97171a3be0ed5c5d"}},"376e4649743b400fa36da2bfae2327fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_29936308b1b6459eb24902806373b4f7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 35/? [12:58&lt;00:00, 22.25s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3dba1003f0184014ae40250b7d02a623"}},"c0d60302944744fab6708d9df2549a8b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6b04510fe3c440de97171a3be0ed5c5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"29936308b1b6459eb24902806373b4f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3dba1003f0184014ae40250b7d02a623":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e7fb156e9a2243fb8a3f468af16a7e3b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_38783bad72224477b3a86c07381b830f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e51d5fbaf2824ea3a5b634ff61e71be7","IPY_MODEL_51de6305284e4c83a3d0e00d245de034"]}},"38783bad72224477b3a86c07381b830f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e51d5fbaf2824ea3a5b634ff61e71be7":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_08927b6a4cb04ec69cc4f51504e62369","_dom_classes":[],"description":"100%","_model_name":"IntProgressModel","bar_style":"success","max":35,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":35,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8fcfd5eceb05440bb27ad34d72cde58a"}},"51de6305284e4c83a3d0e00d245de034":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_063f5b76287c4ef090e4e0fb8139f24e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 35/35 [00:34&lt;00:00,  1.00it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5750c5883a0d48509e12aef2f8528b0c"}},"08927b6a4cb04ec69cc4f51504e62369":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8fcfd5eceb05440bb27ad34d72cde58a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"063f5b76287c4ef090e4e0fb8139f24e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5750c5883a0d48509e12aef2f8528b0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"384d144049594800ae9e7e8b101410d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b0b93cf804f246f9a331539f796de04a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_41a61cd56d294533b108ae0f3dee4eda","IPY_MODEL_612ed5288f1c45848fa2f03a4444247d"]}},"b0b93cf804f246f9a331539f796de04a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"41a61cd56d294533b108ae0f3dee4eda":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_db504f1c5d6749cb8c431292e23dfe07","_dom_classes":[],"description":"  0%","_model_name":"IntProgressModel","bar_style":"","max":782,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7b16dfdb9e0a4753846d2c9d0c00c09e"}},"612ed5288f1c45848fa2f03a4444247d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_431c69ff4b354c8d86a8743afbf02af3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/782 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9710bcbab8c3416588726488ef5c3ee9"}},"db504f1c5d6749cb8c431292e23dfe07":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7b16dfdb9e0a4753846d2c9d0c00c09e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"431c69ff4b354c8d86a8743afbf02af3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9710bcbab8c3416588726488ef5c3ee9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"X5eFnvXeD6pM","colab_type":"code","outputId":"179adb5d-bf36-4136-eb8a-68a3f32d8e7e","executionInfo":{"status":"ok","timestamp":1586683276446,"user_tz":240,"elapsed":1673,"user":{"displayName":"Raghav Gupta","photoUrl":"","userId":"17726055425883616186"}},"colab":{"base_uri":"https://localhost:8080/","height":382}},"source":["from pathlib import Path\n","import os\n","from collections import Counter\n","import numpy as np\n","import time\n","from tqdm.notebook import tqdm\n","\n","np.random.seed(8080)\n","\n","data_path = Path(\"/content/drive/My Drive/Adv Projects in ML/data\")\n","print(data_path)\n","print(os.listdir(data_path))\n","\n","os.chdir(\"/content/drive/My Drive/Adv Projects in ML/\")\n","\n","!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Adv Projects in ML/data\n","['train.lang2', 'unaligned.en', 'unaligned.fr', 'train.lang1', 'split_train.lang1', 'split_val.lang2', 'split_train.lang2', 'split_val.lang1', 'unalignedtry.en', 'split_train_unaligned_tokenized_rempunc.en', 'split_val_unaligned_tokenized_rempunc.en', 'split_train_unaligned_tokenized.en', 'split_val_unaligned_tokenized.en', 'split_train_unaligned_tokenized_rempunc.fr', 'split_val_unaligned_tokenized_rempunc.fr', 'split_train_unaligned_tokenized.fr', 'split_val_unaligned_tokenized.fr', 'bpe', 'unaligned_tokenized_rempunc.en']\n","Sun Apr 12 09:21:15 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_4Yrlb9t-TZ8","colab_type":"code","outputId":"303f0202-4906-488d-dc4c-cb16c8302fbd","executionInfo":{"status":"ok","timestamp":1586683280435,"user_tz":240,"elapsed":2124,"user":{"displayName":"Raghav Gupta","photoUrl":"","userId":"17726055425883616186"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","from transformer import Transformer, CustomSchedule, create_masks\n","\n","print(\"Tensorflow version \" + tf.__version__)\n","\n","tf.random.set_seed(8080)\n","# make sure numpy seeded"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Tensorflow version 2.2.0-rc2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KcNjXYrv_mYF","colab_type":"code","outputId":"f6a34658-091e-4fb6-a873-fb1cc8918255","executionInfo":{"status":"ok","timestamp":1586683280773,"user_tz":240,"elapsed":859,"user":{"displayName":"Raghav Gupta","photoUrl":"","userId":"17726055425883616186"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# read data\n","with open(data_path/\"split_train.lang1\",\"r\") as f:\n","    english = f.read()\n","print(len(english.split(\"\\n\")), english[:200])\n","    \n","with open(data_path/\"split_train.lang2\",\"r\") as f:\n","    french = f.read()\n","print(len(french.split(\"\\n\")), french[:200])\n","\n","with open(data_path/\"split_val.lang1\",\"r\") as f:\n","    english_val = f.read()\n","print(len(english_val.split(\"\\n\")), english_val[:200])\n","\n","with open(data_path/\"split_val.lang2\",\"r\") as f:\n","    french_val = f.read()\n","print(len(french_val.split(\"\\n\")), french_val[:200])\n","\n","# create vocab\n","english_vocab = list(set(english.replace(\"\\n\", \" <eos> \").split()))\n","french_vocab = list(set(french.replace(\"\\n\", \" <eos> \").split()))\n","len(english_vocab), len(french_vocab)\n","\n","english_counter = Counter(english.replace(\"\\n\", \" <eos> \").split())\n","french_counter = Counter(french.replace(\"\\n\", \" <eos> \").split())\n","len(english_counter), len(french_counter)\n","\n","english_counter.update({\"<unk>\":0})\n","french_counter.update({\"<unk>\":0})\n","english_counter.update({\"<start>\":0})\n","french_counter.update({\"<start>\":0})\n","len(english_counter), len(french_counter)\n","\n","english_vocab = list(english_counter.keys())\n","french_vocab = list(french_counter.keys())\n","\n","# # trim vocab to 10k+2, 12k+2\n","# english_vocab = [\"<start>\",\"<unk>\"]\n","# for i in english_counter.most_common(10000):\n","#   english_vocab.append(i[0])\n","# french_vocab = [\"<start>\",\"<unk>\"]\n","# for i in french_counter.most_common(12000):\n","#   french_vocab.append(i[0])\n","\n","english_word2id = {}\n","english_id2word = {}\n","french_word2id = {}\n","french_id2word = {}\n","\n","# start enumerate from 1 so that 0 is reserved for padding seqs \n","for i, w in enumerate(english_vocab, start=1):\n","  english_word2id[w] = i\n","  english_id2word[i] = w\n","\n","for i, w in enumerate(french_vocab, start=1):\n","  french_word2id[w] = i\n","  french_id2word[i] = w\n","\n","len(english_word2id), len(english_id2word), len(french_word2id), len(french_id2word)\n","\n","def transform_data(english_lang1, french_lang2):\n","  english_lines = english_lang1.split(\"\\n\")\n","  french_lines = french_lang2.split(\"\\n\")\n","\n","  data_english = []\n","  data_french = []\n","\n","  for line in english_lines:\n","    line2id = [english_word2id[\"<start>\"]]\n","    for word in line.split():\n","      try:\n","        line2id.append(english_word2id[word])\n","      except:\n","        line2id.append(english_word2id[\"<unk>\"])\n","    line2id.append(english_word2id[\"<eos>\"])\n","    data_english.append(line2id)\n","\n","  for line in french_lines:\n","    line2id = [french_word2id[\"<start>\"]]\n","    for word in line.split():\n","      try:\n","        line2id.append(french_word2id[word])\n","      except:\n","        line2id.append(french_word2id[\"<unk>\"])\n","    line2id.append(french_word2id[\"<eos>\"])\n","    data_french.append(line2id)\n","\n","  print(len(data_english), len(data_french))\n","  return data_english, data_french\n","\n","data_english, data_french = transform_data(english, french)\n","data_english_val, data_french_val = transform_data(english_val, french_val)\n","\n","english_id2word[54], len(data_english), len(data_french), len(data_english_val), len(data_french_val)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["8800 as mr de castro is not present mr le foll who is replacing mr de castro has the floor\n","on the other hand if you 're visiting an underdeveloped country and 25 dollars buys you a gourmet meal it 's exorb\n","8800 Comme M. De Castro est absent , M. Le Foll , qui le remplace , a la parole .\n","D' un autre côté , si vous êtes dans un pays en voie de développement , où 25 dollars peuvent vous obtenir un repas de luxe\n","2200 what action does the council intend to take in the face of this seriously discriminatory attitude which runs contrary to the principles of the eu\n","where would you like to go next\n","if that were not enoug\n","2200 Quelles mesures le Conseil compte-t-il adopter face à cette attitude qui constitue une grave discrimination et est contraire aux principes sur lesquels l' Union européenne est fondée ?\n","Où souhaiteriez\n","8800 8800\n","2200 2200\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["('gas', 8800, 8800, 2200, 2200)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"LPm9QdIbpc7F","colab_type":"code","colab":{}},"source":["np.savez(\"data_and_vocab.npz\", data_english=data_english, data_french=data_french, data_english_val=data_english_val, data_french_val=data_french_val, \n","         english_word2id=english_word2id, english_id2word=english_id2word, french_word2id=french_word2id,french_id2word=french_id2word)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JGcYVItBC8lg","colab_type":"code","outputId":"a4eea5a5-50ed-4227-99f9-feac406f5eca","executionInfo":{"status":"ok","timestamp":1586683287576,"user_tz":240,"elapsed":325,"user":{"displayName":"Raghav Gupta","photoUrl":"","userId":"17726055425883616186"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["BUFFER_SIZE = len(data_english)\n","BATCH_SIZE = 64\n","EPOCHS = 50\n","print(\"No. of batches: \", np.ceil(len(data_english)/BATCH_SIZE))\n","\n","# transformer hyperparams\n","num_layers = 1\n","d_model = 1024\n","dff = 1024\n","num_heads = 8\n","input_vocab_size = len(english_vocab) + 1\n","target_vocab_size = len(french_vocab) + 1\n","dropout_rate = 0.4\n","pe_input = max(max([len(i) for i in data_english]),max([len(i) for i in data_english_val]))\n","pe_target = max(max([len(i) for i in data_french]),max([len(i) for i in data_french_val]))\n","\n","# pe_input = 200\n","# pe_target = 230"],"execution_count":4,"outputs":[{"output_type":"stream","text":["No. of batches:  138.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IWY0Fq9i_C3d","colab_type":"code","colab":{}},"source":["tensor_train = tf.data.Dataset.from_tensor_slices((\n","    tf.keras.preprocessing.sequence.pad_sequences(data_english, padding='post'),\n","    tf.keras.preprocessing.sequence.pad_sequences(data_french, padding='post')\n",")).shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=False)\n","tensor_val = tf.data.Dataset.from_tensor_slices((\n","    tf.keras.preprocessing.sequence.pad_sequences(data_english_val, padding='post'),\n","    tf.keras.preprocessing.sequence.pad_sequences(data_french_val, padding='post')\n",")).batch(BATCH_SIZE, drop_remainder=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GDrlqTOdCnNj","colab_type":"code","outputId":"c5ba2668-9b02-4123-f8ce-35bca7ea95f6","executionInfo":{"status":"ok","timestamp":1586683292331,"user_tz":240,"elapsed":944,"user":{"displayName":"Raghav Gupta","photoUrl":"","userId":"17726055425883616186"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["transformer = Transformer(\n","    num_layers=num_layers, d_model=d_model, num_heads=num_heads, dff=dff, \n","    input_vocab_size=input_vocab_size, target_vocab_size=target_vocab_size, \n","    pe_input=pe_input, pe_target=pe_target, rate=dropout_rate)\n","\n","temp_input = tf.random.uniform((BATCH_SIZE, pe_input), dtype=tf.int64, minval=0, maxval=200)\n","temp_target = tf.random.uniform((BATCH_SIZE, pe_target), dtype=tf.int64, minval=0, maxval=200)\n","\n","fn_out, _ = transformer(temp_input, temp_target, training=False, \n","                               enc_padding_mask=None, \n","                               look_ahead_mask=None,\n","                               dec_padding_mask=None)\n","\n","fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([64, 114, 16315])"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"bcxIKWUwEUzl","colab_type":"code","outputId":"41c1e51a-cb13-4f28-a96f-6d87bffddb76","executionInfo":{"status":"ok","timestamp":1586683294527,"user_tz":240,"elapsed":327,"user":{"displayName":"Raghav Gupta","photoUrl":"","userId":"17726055425883616186"}},"colab":{"base_uri":"https://localhost:8080/","height":271}},"source":["transformer.summary()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Model: \"transformer\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","encoder (Encoder)            multiple                  18961408  \n","_________________________________________________________________\n","decoder (Decoder)            multiple                  27208704  \n","_________________________________________________________________\n","dense_16 (Dense)             multiple                  16722875  \n","=================================================================\n","Total params: 62,892,987\n","Trainable params: 62,892,987\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9miA7eqeGGAe","colab_type":"code","colab":{}},"source":["learning_rate = CustomSchedule(d_model)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n","                                     epsilon=1e-9)\n","\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')\n","\n","train_loss = tf.keras.metrics.Mean(name='loss')\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n","    name='train_accuracy')\n","\n","val_loss = tf.keras.metrics.Mean(name='loss')\n","val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n","    name='val_accuracy')\n","\n","def loss_function(real, pred):\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  loss_ = loss_object(real, pred)\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype)\n","  loss_ *= mask\n","  \n","  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_LMjos4JGtKM","colab_type":"code","colab":{}},"source":["experiment_number = \"7_smaller_1_1024_\"\n","\n","checkpoint_path = \"./checkpoints/train\"+experiment_number\n","\n","ckpt = tf.train.Checkpoint(transformer=transformer,\n","                           optimizer=optimizer)\n","\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n","\n","writer_train = tf.summary.create_file_writer(\"log_dir/\"+experiment_number+\"_train\")\n","writer_val = tf.summary.create_file_writer(\"log_dir/\"+experiment_number+\"_val\")\n","\n","# # if a checkpoint exists, restore the latest checkpoint.\n","# if ckpt_manager.latest_checkpoint:\n","#   ckpt.restore(ckpt_manager.latest_checkpoint)\n","#   print ('Latest checkpoint restored!!')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dQCsdQOGI8j4","colab_type":"code","colab":{}},"source":["# The @tf.function trace-compiles train_step into a TF graph for faster\n","# execution. The function specializes to the precise shape of the argument\n","# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n","# batch sizes (the last batch is smaller), use input_signature to specify\n","# more generic shapes.\n","\n","train_step_signature = [\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n","]\n","\n","@tf.function(input_signature=train_step_signature)\n","def train_step(inp, tar):\n","  \n","  tar_inp = tar[:, :-1]\n","  tar_real = tar[:, 1:]\n","  \n","  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n","\n","  with tf.GradientTape() as tape:\n","    predictions, _ = transformer(inp, tar_inp, \n","                                 True, \n","                                 enc_padding_mask, \n","                                 combined_mask, \n","                                 dec_padding_mask)\n","    loss = loss_function(tar_real, predictions)\n","\n","  gradients = tape.gradient(loss, transformer.trainable_variables)\n","  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n","  \n","  train_loss(loss)\n","  train_accuracy(tar_real, predictions)\n","\n","@tf.function(input_signature=train_step_signature)\n","def val_step(inp, tar):\n","  \n","  tar_inp = tar[:, :-1]\n","  tar_real = tar[:, 1:]\n","  \n","  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n","\n","  predictions, _ = transformer(inp, tar_inp, \n","                                False, \n","                                enc_padding_mask, \n","                                combined_mask, \n","                                dec_padding_mask)\n","  loss = loss_function(tar_real, predictions)\n","  \n","  val_loss(loss)\n","  val_accuracy(tar_real, predictions)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"plonJ7XgJeDg","colab_type":"code","colab":{}},"source":["best_val_loss = np.inf\n","\n","for epoch in range(EPOCHS):\n","  start = time.time()\n","  \n","  train_loss.reset_states()\n","  train_accuracy.reset_states()\n","  \n","  val_loss.reset_states()\n","  val_accuracy.reset_states()\n","  \n","  for (batch, (inp, tar)) in tqdm(enumerate(tensor_train)):\n","    train_step(inp, tar)\n","    if batch % 50 == 0:\n","      print ('Epoch {} Batch {} Training Loss {:.4f} Accuracy {:.4f}'.format(\n","          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n","    \n","  print ('Epoch {} Training Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n","                                                train_loss.result(), \n","                                                train_accuracy.result()))\n","  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n","\n","  with writer_train.as_default():\n","    tf.summary.scalar('train_loss', train_loss.result(), step=epoch)\n","\n","  print(\"validating\")\n","  for (batch, (inp, tar)) in enumerate(tensor_val):\n","    val_step(inp, tar)\n","  \n","  print ('Epoch {} Validation Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n","                                            val_loss.result(), \n","                                            val_accuracy.result()))\n","  if best_val_loss > val_loss.result():\n","    best_val_loss = val_loss.result()\n","    ckpt_save_path = ckpt_manager.save()\n","    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n","                                                         ckpt_save_path))\n","  with writer_val.as_default():\n","    tf.summary.scalar('val_loss', val_loss.result(), step=epoch)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bR9M8XwL05hX","colab_type":"text"},"source":["Evaluate best model"]},{"cell_type":"code","metadata":{"id":"u6WVgDZXqo1F","colab_type":"code","outputId":"d32b5367-069b-466e-bcd9-033406ee32d1","executionInfo":{"status":"ok","timestamp":1586671348774,"user_tz":240,"elapsed":2005,"user":{"displayName":"Raghav Gupta","photoUrl":"","userId":"17726055425883616186"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# load model\n","\n","# if a checkpoint exists, restore the latest checkpoint.\n","if ckpt_manager.latest_checkpoint:\n","  ckpt.restore(ckpt_manager.latest_checkpoint)\n","  print ('Latest checkpoint restored!!')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Latest checkpoint restored!!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ljGfecGyyfeC","colab_type":"code","outputId":"f5b435df-500b-439d-9278-70a20989f28e","executionInfo":{"status":"ok","timestamp":1586671393092,"user_tz":240,"elapsed":871,"user":{"displayName":"Raghav Gupta","photoUrl":"","userId":"17726055425883616186"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["transformer"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<transformer.Transformer at 0x7fb433ceed30>"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"CF-mUwyO0u7l","colab_type":"code","outputId":"5e38a006-aa84-4e3d-aa38-0aab4f8e310a","executionInfo":{"status":"ok","timestamp":1586671419720,"user_tz":240,"elapsed":6633,"user":{"displayName":"Raghav Gupta","photoUrl":"","userId":"17726055425883616186"}},"colab":{"base_uri":"https://localhost:8080/","height":85,"referenced_widgets":["8836bb2b6acc427ebb184f0bb56e610f","970e2f61c5c7482b806f87bb176b9c95","9b67c58409b14e14a1def0307c65e5cc","2e4bfcf2398e4363a1a0c0c649a71de7","4689346d8cef48629fce05753d0925eb","171f64430e624f76849b358ccc995f3d","4edde0098b9d401ba066bf520e0f4ee3","42261fa4c1184f2fb184e9e1bb81a903"]}},"source":["val_loss.reset_states()\n","val_accuracy.reset_states()\n","  \n","for (batch, (inp, tar)) in tqdm(enumerate(tensor_val)):\n","  val_step(inp, tar)\n","  \n","print ('Validation Loss {:.4f} Accuracy {:.4f}'.format(\n","                                          val_loss.result(), \n","                                          val_accuracy.result()))\n","  "],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8836bb2b6acc427ebb184f0bb56e610f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Validation Loss 4.6330 Accuracy 0.0759\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qrKQhIW96Jk-","colab_type":"code","colab":{}},"source":["def generate_predictions(inp_sentences):\n","\n","  if len(inp_sentences.get_shape())==1:\n","    encoder_input = tf.expand_dims(inp_sentences, 0)\n","    decoder_input = [french_word2id[\"<start>\"]]\n","    output = tf.expand_dims(decoder_input, 0)\n","\n","  else:\n","    encoder_input = inp_sentences\n","    decoder_input = [french_word2id[\"<start>\"]]*inp_sentences.get_shape()[0]\n","    output = tf.expand_dims(decoder_input, -1)\n","\n","\n","  # encoder_input = tf.expand_dims(inp_sentence, 0)\n","  \n","  # decoder_input = [french_word2id[\"<start>\"]]\n","  # output = tf.expand_dims(decoder_input, 0)\n","  \n","  for i in range(pe_target):\n","    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n","        encoder_input, output)\n","  \n","    # predictions.shape == (batch_size, seq_len, vocab_size)\n","    predictions, attention_weights = transformer(encoder_input, \n","                                                 output,\n","                                                 False,\n","                                                 enc_padding_mask,\n","                                                 combined_mask,\n","                                                 dec_padding_mask)\n","    \n","    # select the last word from the seq_len dimension\n","    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n","\n","    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n","    \n","    # # return the result if all the seqs has the end token\n","    if tf.reduce_sum(tf.cast((tf.reduce_sum(tf.cast(output == french_word2id[\"<eos>\"], tf.float32),axis=1)>0), tf.float32)) == inp.get_shape()[0]:\n","      return output, attention_weights\n","    \n","    # concatentate the predicted_id to the output which is given to the decoder\n","    # as its input.\n","    output = tf.concat([output, predicted_id], axis=-1)\n","\n","  # return tf.squeeze(output, axis=0), attention_weights\n","  return output, attention_weights"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bVGAfzoj3N1N","colab_type":"code","outputId":"2e02242f-220a-4738-9aae-639615b71911","executionInfo":{"status":"ok","timestamp":1586671577697,"user_tz":240,"elapsed":125943,"user":{"displayName":"Raghav Gupta","photoUrl":"","userId":"17726055425883616186"}},"colab":{"base_uri":"https://localhost:8080/","height":630,"referenced_widgets":["6a4a078904c94ce79a51213166688c9f","a65149548a084913b53750ddc00da1a6","6c8556bdaa93487a848bf08cef6e1178","376e4649743b400fa36da2bfae2327fd","c0d60302944744fab6708d9df2549a8b","6b04510fe3c440de97171a3be0ed5c5d","29936308b1b6459eb24902806373b4f7","3dba1003f0184014ae40250b7d02a623"]}},"source":["all_preds = []\n","for (batch_i, (inp, tar)) in tqdm(enumerate(tensor_val)):\n","  preds, attention = generate_predictions(inp)\n","  all_preds.append(preds)"],"execution_count":17,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6a4a078904c94ce79a51213166688c9f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["47\n","94\n","44\n","47\n","49\n","57\n","47\n","46\n","49\n","46\n","47\n","40\n","49\n","48\n","45\n","55\n","48\n","46\n","40\n","49\n","66\n","49\n","79\n","72\n","52\n","61\n","53\n","44\n","49\n","42\n","47\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5rd4TtZWAzLf","colab_type":"code","outputId":"63e5c25d-ca60-46cc-9ed2-5573a7052999","executionInfo":{"status":"ok","timestamp":1586672196411,"user_tz":240,"elapsed":793,"user":{"displayName":"Raghav Gupta","photoUrl":"","userId":"17726055425883616186"}},"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["e7fb156e9a2243fb8a3f468af16a7e3b","38783bad72224477b3a86c07381b830f","e51d5fbaf2824ea3a5b634ff61e71be7","51de6305284e4c83a3d0e00d245de034","08927b6a4cb04ec69cc4f51504e62369","8fcfd5eceb05440bb27ad34d72cde58a","063f5b76287c4ef090e4e0fb8139f24e","5750c5883a0d48509e12aef2f8528b0c"]}},"source":["translated_sentences = []\n","\n","for k in tqdm(all_preds):\n","  for i in k:\n","    sentence_french = []\n","    for j in i.numpy()[1:]:\n","      if j==0 or j==french_word2id[\"<eos>\"]:\n","        break\n","      sentence_french.append(french_id2word[j])\n","\n","    sentence_french = \" \".join(sentence_french)\n","\n","    translated_sentences.append(sentence_french)\n","\n","translated_sentences = \"\\n\".join(translated_sentences)\n","\n","with open(\"predictions.txt\",\"w\") as f:\n","  f.write(translated_sentences)"],"execution_count":18,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e7fb156e9a2243fb8a3f468af16a7e3b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=35), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ee2vGd98URGB","colab_type":"code","outputId":"ab334b84-7def-48c0-9038-6172d33fce78","executionInfo":{"status":"ok","timestamp":1586672202101,"user_tz":240,"elapsed":4658,"user":{"displayName":"Raghav Gupta","photoUrl":"","userId":"17726055425883616186"}},"colab":{"base_uri":"https://localhost:8080/","height":108}},"source":["!pip install sacrebleu\n","!python evaluator.py --input-file-path ./predictions.txt --target-file-path ./data/split_val.lang2 --do-not-run-model "],"execution_count":19,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: sacrebleu in /usr/local/lib/python3.6/dist-packages (1.4.6)\n","Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (0.996.5)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (1.6.0)\n","Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n","final avg bleu score: 9.73\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IyhjKQAdF2Ts","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tX4Bp-fPl-sZ","colab_type":"text"},"source":["Self-Training Monolingual Data Generation"]},{"cell_type":"code","metadata":{"id":"aOTJwCVeDEtg","colab_type":"code","colab":{}},"source":["amount_data_start = 100000\n","amount_data_end = 200000"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KI-dbSb4mCYe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"d9f1d521-ee59-4533-ce80-465ae6069d78","executionInfo":{"status":"ok","timestamp":1586683325604,"user_tz":240,"elapsed":1003,"user":{"displayName":"Raghav Gupta","photoUrl":"","userId":"17726055425883616186"}}},"source":["with open(data_path/\"unaligned_tokenized_rempunc.en\",\"r\") as f:\n","    english_monolingual = f.read().strip().lower()\n","print(len(english_monolingual.split(\"\\n\")), english_monolingual[:200])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["474000 for the second phase of the trials we just had different sizes small medium large and extra - large it 's true\n","geng had been my host the previous january when i was the first us defense secretary to v\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sJRokEGnmjwh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"1f8c8626-fbeb-4420-a06a-d2972dc63b99","executionInfo":{"status":"ok","timestamp":1586683332668,"user_tz":240,"elapsed":1000,"user":{"displayName":"Raghav Gupta","photoUrl":"","userId":"17726055425883616186"}}},"source":["def transform_test_data(lang1, dict_word2id, amount_data_start=None,amount_data_end=None):\n","  lines = lang1.split(\"\\n\")\n","  if amount_data_start or amount_data_end:\n","    lines = lines[amount_data_start:amount_data_end]\n","  data = []\n","\n","  for line in lines:\n","    line2id = [dict_word2id[\"<start>\"]]\n","    for word in line.split():\n","      try:\n","        line2id.append(dict_word2id[word])\n","      except:\n","        line2id.append(dict_word2id[\"<unk>\"])\n","    line2id.append(dict_word2id[\"<eos>\"])\n","    data.append(line2id)\n","\n","  return data\n","\n","english_monolingual_data = transform_test_data(english_monolingual, english_word2id, amount_data_start, amount_data_end)\n","len(english_monolingual_data)"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["100000"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"950vucyyn_uL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"307d194b-49ba-4179-9cce-3873c1bbcc52","executionInfo":{"status":"ok","timestamp":1586683334564,"user_tz":240,"elapsed":370,"user":{"displayName":"Raghav Gupta","photoUrl":"","userId":"17726055425883616186"}}},"source":["max([len(i) for i in english_monolingual_data])"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["112"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"5Sn6FZlqokKC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":90},"outputId":"b6c85032-05b3-47ce-b61d-c27e64518cc8","executionInfo":{"status":"ok","timestamp":1586683346889,"user_tz":240,"elapsed":4944,"user":{"displayName":"Raghav Gupta","photoUrl":"","userId":"17726055425883616186"}}},"source":["with open(data_path/\"unaligned.fr\",\"r\") as f:\n","    french_monolingual = f.read().strip().lower()\n","print(len(french_monolingual.split(\"\\n\")), french_monolingual[:200])\n","french_monolingual_data = transform_test_data(french_monolingual, french_word2id)\n","print(len(french_monolingual_data))\n","max([len(i) for i in french_monolingual_data])"],"execution_count":16,"outputs":[{"output_type":"stream","text":["474000 nous n’aurions pas pu dégager d’accord sur un calendrier de conclusion de la cig sans l’engagement politique de mes collègues du conseil européen.\n","(de) madame la présidente, monsieur le commissaire, m\n","474000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["220"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"2A0v1neEoBrq","colab_type":"code","colab":{}},"source":["pe_input = max([len(i) for i in english_monolingual_data])\n","pe_target = max([len(i) for i in french_monolingual_data])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0YZKlYXUpZlk","colab_type":"code","colab":{}},"source":["tensor_test = tf.data.Dataset.from_tensor_slices((\n","    tf.keras.preprocessing.sequence.pad_sequences(english_monolingual_data, padding='post')\n",")).batch(BATCH_SIZE, drop_remainder=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UFKv4PkuqE9g","colab_type":"code","colab":{}},"source":["transformer = Transformer(\n","    num_layers=num_layers, d_model=d_model, num_heads=num_heads, dff=dff, \n","    input_vocab_size=input_vocab_size, target_vocab_size=target_vocab_size, \n","    pe_input=pe_input, pe_target=pe_target, rate=dropout_rate)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cyJk6fUsqTsA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"8dd6da1d-139e-49d5-afa1-fef257b0af60","executionInfo":{"status":"ok","timestamp":1586683353297,"user_tz":240,"elapsed":315,"user":{"displayName":"Raghav Gupta","photoUrl":"","userId":"17726055425883616186"}}},"source":["experiment_number = \"7_smaller_1_1024_\"\n","\n","checkpoint_path = \"./checkpoints/train\"+experiment_number\n","\n","ckpt = tf.train.Checkpoint(transformer=transformer,\n","                           optimizer=optimizer)\n","\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n","\n","if ckpt_manager.latest_checkpoint:\n","  ckpt.restore(ckpt_manager.latest_checkpoint)\n","  print ('Latest checkpoint restored!!')"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Latest checkpoint restored!!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XWO2I4uEqhR4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["384d144049594800ae9e7e8b101410d2","b0b93cf804f246f9a331539f796de04a","41a61cd56d294533b108ae0f3dee4eda","612ed5288f1c45848fa2f03a4444247d","db504f1c5d6749cb8c431292e23dfe07","7b16dfdb9e0a4753846d2c9d0c00c09e","431c69ff4b354c8d86a8743afbf02af3","9710bcbab8c3416588726488ef5c3ee9"]},"outputId":"12ed3f6b-43ac-4a54-ab64-937dc5b99f42"},"source":["all_preds = []\n","for batch_i, inp in tqdm(enumerate(tensor_test.unbatch().batch(128)),total=len(english_monolingual_data) // 128 + 1):\n","  preds, attention = generate_predictions(inp)\n","  all_preds.append(preds)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"384d144049594800ae9e7e8b101410d2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"jWEkOtRUq45R","colab_type":"code","colab":{}},"source":["translated_sentences = []\n","\n","for k in tqdm(all_preds):\n","  for i in k:\n","    sentence_french = []\n","    for j in i.numpy()[1:]:\n","      if j==0 or j==french_word2id[\"<eos>\"]:\n","        break\n","      sentence_french.append(french_id2word[j])\n","\n","    sentence_french = \" \".join(sentence_french)\n","\n","    translated_sentences.append(sentence_french)\n","\n","translated_sentences = \"\\n\".join(translated_sentences)\n","\n","with open(\"predictions_english_monolingual_\"+str(amount_data_start)+\"_\"+str(amount_data_end)+\".txt\",\"w\") as f:\n","  f.write(translated_sentences)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Djy0dvXrAU4","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}