{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNT_with_attention_synt.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2z7lznOGKw9",
        "colab_type": "code",
        "outputId": "d0ce8f30-8f34-4e4f-d759-07bf248d4c18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo_GTNyGHEIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "import utils\n",
        "import model_encdec\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Sl4pqcTokE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = '/content/drive/My Drive/IFT6759-PROJECT2/config5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IyQ6TwTGr4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# path_source = ['/content/drive/My Drive/IFT6759-PROJECT2/data/split_train.lang1', '/content/drive/My Drive/IFT6759-PROJECT2/data/unaligned.fr']\n",
        "# path_destination = ['/content/drive/My Drive/IFT6759-PROJECT2/data/split_train.lang2.txt', '/content/drive/My Drive/IFT6759-PROJECT2/data/unaligned.fr']\n",
        "\n",
        "path_source = '/content/drive/My Drive/IFT6759-PROJECT2/data/split_train.lang1_95'\n",
        "path_destination = '/content/drive/My Drive/IFT6759-PROJECT2/data/split_train.lang2_95'\n",
        "\n",
        "\n",
        "# print(path_source[0])\n",
        "# print(path_source[1])\n",
        "\n",
        "# print(path_destination[0])\n",
        "# print(path_destination[1])\n",
        "# path_source = '/content/drive/My Drive/IFT6759-PROJECT2/data/train.lang1'\n",
        "# path_destination = '/content/drive/My Drive/IFT6759-PROJECT2/data/train.lang2'\n",
        "\n",
        "num_examples = 10450\n",
        "\n",
        "input_tensor_train, target_tensor_train, inp_lang, targ_lang = utils.load_dataset(path_source, path_destination, num_examples)\n",
        "max_length_targ, max_length_inp = utils.max_length(target_tensor_train), utils.max_length(input_tensor_train)\n",
        "\n",
        "# input_tensor_train, target_tensor_train, inp_lang, targ_lang = utils.load_dataset_2_files(path_source, path_destination, num_examples, 3)\n",
        "# max_length_targ, max_length_inp = utils.max_length(target_tensor_train), utils.max_length(input_tensor_train)\n",
        "\n",
        "\n",
        "# max_length_targ, max_length_inp = utils.max_length(target_tensor), utils.max_length(input_tensor)\n",
        "# input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2, shuffle=False)\n",
        "\n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 16\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 128\n",
        "units = 256\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor_train, target_tensor_train, test_size=0.2, shuffle=True)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val))\n",
        "val_dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "encoder = model_encdec.Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "attention_layer = model_encdec.BahdanauAttention(8)\n",
        "decoder = model_encdec.Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0Atc2ynhjnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\"\"\"## Checkpoints (Object-based saving)\"\"\"\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUZc7gb6R452",
        "colab_type": "code",
        "outputId": "38cde68b-4b5a-4224-dfaf-dad6e642b4a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "input_tensor_train.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8360, 94)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W-eyVAebM6a",
        "colab_type": "code",
        "outputId": "8b053918-eb4f-4c30-fe50-776256808324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "target_tensor_train.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8360, 106)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_4l0ixXUZZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss\n",
        "\n",
        "@tf.function\n",
        "def val_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "  # Teacher forcing - feeding the target as the next input\n",
        "  for t in range(1, targ.shape[1]):\n",
        "    # passing enc_output to the decoder\n",
        "    predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "    loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "    # using teacher forcing\n",
        "    dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  return batch_loss\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)\n",
        "\n",
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = utils.preprocess_sentence(sentence)\n",
        "  # print(sentence)\n",
        "\n",
        "  # inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "\n",
        "  inputs = []\n",
        "\n",
        "  for i in sentence.split(' '):\n",
        "    if inp_lang.word_index.get(i) != None:\n",
        "      inputs.append(inp_lang.word_index.get(i))\n",
        "\n",
        "  # print(inputs) \n",
        "\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "    else:\n",
        "      result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot\n",
        "\n",
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  # plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-H72kWPbpED",
        "colab_type": "code",
        "outputId": "4ee5b4ac-bd02-4e21-b590-46021cbfdaf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.InitializationOnlyStatus at 0x7fde978ed588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cdsOGEmGyDN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "26a8456c-0e28-4dbb-d8ed-43230cc76f75"
      },
      "source": [
        "EPOCHS = 3\n",
        "\n",
        "best_val_loss = np.inf\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Training Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "      \n",
        "\n",
        "  print('Epoch {} Training Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = val_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "  total_loss_ = total_loss / steps_per_epoch\n",
        "  print('Epoch {} Validation Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss_))\n",
        "\n",
        "  if best_val_loss > total_loss_:\n",
        "    best_val_loss = total_loss_\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    print(\"-- saving at best validation loss\")\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Training Loss 0.0026\n",
            "Time taken for 1 epoch 0.3492105007171631 sec\n",
            "\n",
            "Epoch 1 Validation Loss 0.0033\n",
            "-- saving at best validation loss\n",
            "Epoch 2 Training Loss 0.0035\n",
            "Time taken for 1 epoch 0.33395934104919434 sec\n",
            "\n",
            "Epoch 2 Validation Loss 0.0036\n",
            "Epoch 3 Training Loss 0.0029\n",
            "Time taken for 1 epoch 0.33498334884643555 sec\n",
            "\n",
            "Epoch 3 Validation Loss 0.0030\n",
            "-- saving at best validation loss\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImW1YQ0bG0Tq",
        "colab_type": "code",
        "outputId": "b5d3fe19-9739-4678-90b7-d6018c193f1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "\n",
        "# checkpoint.restore('/content/drive/My Drive/IFT6759-PROJECT2/synt_17600-4/synt_17600-4/ckpt-33')\n",
        "\n",
        "translate(u'thank you.')\n",
        "\n",
        "translate(u'i need to go the cinema')\n",
        "\n",
        "translate(u'it is time to sleep')\n",
        "\n",
        "translate(u'i would like to go to friends house')\n",
        "\n",
        "translate(u'i would like to see him again')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> thank you . <end>\n",
            "Predicted translation: merci beaucoup . \n",
            "Input: <start> i need to go the cinema <end>\n",
            "Predicted translation: je dois , le droit a la limitation de poste . \n",
            "Input: <start> it is time to sleep <end>\n",
            "Predicted translation: il est temps au ski . \n",
            "Input: <start> i would like to go to friends house <end>\n",
            "Predicted translation: je voudrais attirer par semaine . \n",
            "Input: <start> i would like to see him again <end>\n",
            "Predicted translation: je voudrais que ca a nouveau . \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nvZmCHy2yqFl",
        "colab": {}
      },
      "source": [
        "path_source_val = '/content/drive/My Drive/IFT6759-PROJECT2/data/split_val.lang1_05'\n",
        "path_destination_val = '/content/drive/My Drive/IFT6759-PROJECT2/data/split_val.lang2_05'\n",
        "\n",
        "validation_input = []\n",
        "validation_results = []\n",
        "validation_target = []\n",
        "\n",
        "lines_source_val = io.open(path_source_val, encoding='UTF-8').read().strip().split('\\n')\n",
        "lines_destination_val = io.open(path_destination_val, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "# result, sentence, attention_plot = evaluate(lines_source_val[6])\n",
        "\n",
        "for index, l in enumerate(lines_source_val):\n",
        "    result, sentence, attention_plot = evaluate(l)\n",
        "    validation_results.append(result)\n",
        "    validation_input.append(l)\n",
        "    validation_target.append(lines_destination_val[index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNH_jf9-yri0",
        "colab_type": "code",
        "outputId": "0a9c2192-c2a3-4174-8e76-96616e1c9c6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "validation_results[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['je suis , et je vais en un . ',\n",
              " 'je suis d accord par plusieurs fois que je me suis implique la premiere fois que je me suis ici d un des plus interessants des femmes . ',\n",
              " 'les depenses , le probleme de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question de la question ',\n",
              " 'il est la tactique deployee par les etats membres de l aide soient grace aux citoyens . ',\n",
              " 'quelque chose que j ai vu , en ai vu , en ai vu , en ai vu , en ai vu , en ai vu , en ai vu , en ai vu , en ai vu , en ai vu , en ai vu , en ai vu , en ai vu , en ai vu , en ai vu , en ai vu , en ai vu , en ai vu , en ai vu , en ai vu , en ai vu , en ai vu , en ai vu , en ai vu , en ai vu , en ai vu , en ai vu , en ai ',\n",
              " 'que ce qui se passe en tete et les citoyens europeens et de l europe de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l elargissement de l ',\n",
              " 'on peut etre disposes a present apporter son aide soient disponibles pour imposer des problemes . ',\n",
              " 'j ai cherche que j ai la bienvenue a ma part , je suis la bienvenue a ma part , je suis la bienvenue a ma part , je suis la bienvenue a ma part , je suis la bienvenue a ma part , je suis la bienvenue a ma part , je suis la bienvenue a ma part , je suis la bienvenue a ma part , je suis la bienvenue a ma part , je suis la bienvenue a ma part , je suis la bienvenue a ma part , je suis la bienvenue a ma part , je suis la bienvenue a ma part , je suis la bienvenue a ',\n",
              " 'en ce contexte , l irlande , les gouvernements ne doit pas bien de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de l absence de ',\n",
              " 'j ai dit que la meme chose que j ai vu que j ai vu que j ai vu que j ai vu que j ai vu que j ai vu que j ai vu que j ai vu que j ai vu que j ai vu que j ai vu que j ai vu que j ai vu que j ai vu que j ai vu que j ai vu que j ai vu que j ai vu que j ai vu que j ai vu que j ai vu que j ai vu que j ai vu que j ai vu que j ai vu que j ai vu que j ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2s917BezufP",
        "colab_type": "code",
        "outputId": "dccad238-d052-4823-e248-238a7f39218c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "validation_target[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Je suis Jon M. Chu , et je ne suis pas un danseur . Je ne suis pas un chorégraphe , en réalité je suis un producteur de films , un raconteur d' histoires .\",\n",
              " \"Je rejoins ce qu' ont dit quelques orateurs quant à la situation des femmes .\",\n",
              " \"À Téhéran , le cœur et l' âme politique du pays , seuls moins d' un tiers des électeurs se sont présentés aux urnes .\",\n",
              " 'La capacité des gouvernants des États en la matière est rendue optionnelle . Ils sont pourtant élus par le peuple , eux !',\n",
              " \"Il s' est passé quelque chose quand j' ai commencé à voyager pour V - day il y a huit ans . Je me suis perdue .\",\n",
              " \"Ce qui se passe en Tunisie en ce moment pose question à chacun d' entre nous et pose question à l' Europe , avec tous ses retards et toutes ses erreurs .\",\n",
              " \"Il n' est pas transposable à volonté car chaque État membre présente un contexte qui lui est propre .\",\n",
              " \"J' ai ajouté une pièce à ma maison .\",\n",
              " \"par écrit . - Dans le contexte de la crise de l' euro , les États membres ne doivent plus échapper à des sanctions en cas de dérapage de leurs déficits .\",\n",
              " \"Il y a deux ans , j' ai dit la même chose ici au Parlement , et vous avez voté à une large majorité en faveur de la décharge .\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqLEIfOr1VqW",
        "colab_type": "code",
        "outputId": "c37db554-0687-42d8-ecdd-3dc381f12f06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "validation_input[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"i 'm jon m. chu and i 'm not a dancer i 'm not a choreographer -- i 'm actually a filmmaker a storyteller\",\n",
              " 'i agree with what a few of the speakers said concerning the situation of women',\n",
              " \"in tehran the country 's political heart and soul less than a third of the electorate turned out\",\n",
              " 'it makes the capacity of the leaders of the member states to act in this matter merely optional even though they are the ones elected by the people',\n",
              " 'something happened when i began traveling in v - day eight years ago i got lost',\n",
              " 'what is happening in tunisia at the moment poses questions for all of us and poses questions for europe with all its delays and mistakes',\n",
              " 'it can not be copied arbitrarily since each member state has its own specific conditions',\n",
              " 'i added a room to my house',\n",
              " 'in the context of the euro crisis member states should no longer escape penalties if their deficits get out of control',\n",
              " 'i said the same thing here in parliament two years ago and you voted to discharge by a large majority',\n",
              " 'and some of these animals are probably inspiration for the things you saw in avatar',\n",
              " 'we therefore once again reject the liberalisation of gas and electricity advocating that they should remain in the public sector as the sole guarantee of access to a continuous service offering quality and accessible prices',\n",
              " 'milan – markets and capitalist incentives have great strengths in promoting economic efficiency growth and innovation',\n",
              " 'the code of conduct for commissioners as well as the requirement to provide information including confidential information are welcomed',\n",
              " \"i 'm happy to share a little more love in the world it 's great but here 's your prescription from dr love eight hugs a day\",\n",
              " 'the plane made a perfect landing',\n",
              " 'we need to respect the ratification system of each member state',\n",
              " 'there is milk in the refrigerator',\n",
              " 'the question was not whether there would be a response',\n",
              " 'i think that we should do our utmost firstly to ensure that peace and democracy are in place in iraq itself']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q72Z7Uo5vF4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('validation_input.txt', 'w') as f:\n",
        "    for item in validation_input:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49nZjGULy9hW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('validation_results.txt', 'w') as f:\n",
        "    for item in validation_results:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8Sm4mytvP5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('validation_target.txt', 'w') as f:\n",
        "    for item in validation_target:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDejebuwHWTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import evaluator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeVJjUHI4GKg",
        "colab_type": "code",
        "outputId": "09aacdc9-6289-4237-ed69-a5271da0ddb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install sacrebleu\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.6/dist-packages (1.4.6)\n",
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (0.996.5)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (1.6.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tbfDTRwAGoE",
        "colab_type": "code",
        "outputId": "aa6ce2f0-4cb2-4457-94c6-0d6faf0bfa78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "!python '/content/evaluator.py' --do-not-run-model --target-file-path='/content/validation_results.txt' --input-file-path='/content/drive/My Drive/IFT6759-PROJECT2/data/split_val.lang2_05'\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['5.4', '4.4', '0.1', '2.3', '0.1', '0.7', '2.0', '0.0', '0.3', '0.2', '0.0', '0.6', '8.5', '0.1', '6.3', '7.3', '4.0', '4.8', '4.0', '0.1', '2.2', '0.1', '2.4', '0.2', '5.7', '15.1', '8.9', '2.4', '6.7', '2.3', '3.8', '2.3', '1.9', '2.0', '1.7', '12.4', '11.7', '4.8', '23.6', '2.2', '6.4', '5.0', '0.1', '0.0', '0.0', '8.1', '0.1', '8.9', '0.1', '3.7', '3.8', '4.2', '13.1', '5.1', '0.2', '0.1', '1.3', '4.0', '6.9', '4.5', '1.4', '9.5', '0.1', '2.7', '1.7', '2.0', '2.3', '6.3', '4.2', '0.3', '4.1', '1.8', '2.1', '0.1', '9.7', '4.5', '0.2', '0.0', '4.9', '13.5', '2.4', '3.0', '0.3', '23.6', '1.3', '14.5', '6.3', '0.8', '4.7', '0.0', '0.0', '0.6', '6.2', '7.4', '1.6', '0.7', '3.7', '0.2', '4.9', '0.1', '2.0', '0.2', '2.9', '1.4', '2.0', '3.8', '0.2', '2.7', '0.0', '0.1', '0.3', '2.9', '0.4', '1.3', '5.8', '2.7', '4.5', '2.9', '4.3', '0.4', '2.7', '0.1', '0.1', '0.1', '4.1', '0.0', '0.0', '2.0', '0.5', '4.8', '1.8', '1.8', '1.8', '4.6', '3.8', '0.2', '0.1', '2.4', '0.4', '2.3', '2.4', '1.2', '6.6', '0.1', '0.2', '0.5', '0.0', '12.6', '16.0', '0.1', '2.6', '0.2', '7.8', '1.1', '1.5', '2.7', '5.5', '17.1', '4.2', '4.2', '4.4', '2.7', '2.5', '4.1', '0.0', '23.9', '0.3', '2.4', '0.0', '1.4', '8.1', '0.4', '9.7', '0.5', '2.9', '9.7', '2.0', '7.1', '2.3', '0.2', '3.7', '1.5', '3.5', '0.1', '0.5', '0.6', '0.2', '2.3', '0.0', '3.0', '5.8', '0.4', '0.2', '1.1', '0.3', '6.8', '3.5', '1.9', '1.9', '3.4', '9.3', '3.1', '2.9', '2.8', '0.6', '19.6', '2.6', '0.2', '0.7', '5.0', '0.1', '0.0', '0.1', '5.7', '2.1', '5.4', '3.4', '3.7', '3.7', '4.0', '7.8', '0.4', '1.7', '0.2', '10.3', '2.8', '1.0', '2.4', '3.1', '2.0', '2.5', '3.4', '0.1', '2.5', '1.3', '2.5', '0.2', '6.6', '2.5', '0.1', '14.5', '2.4', '3.1', '8.1', '2.4', '0.0', '2.3', '4.3', '3.0', '4.5', '0.5', '4.2', '2.0', '2.6', '2.3', '0.2', '4.0', '0.1', '4.3', '5.4', '2.4', '0.0', '1.9', '3.1', '2.5', '27.5', '0.2', '6.3', '0.1', '0.9', '0.2', '1.9', '0.3', '1.4', '15.9', '3.7', '0.5', '0.2', '5.5', '4.0', '0.2', '8.1', '0.0', '2.0', '0.1', '0.1', '2.4', '2.1', '0.3', '5.7', '1.6', '1.5', '0.2', '3.6', '0.2', '0.1', '0.0', '1.1', '6.4', '1.6', '4.4', '1.8', '0.2', '0.4', '2.2', '0.6', '4.1', '4.5', '7.1', '2.2', '5.7', '13.5', '0.1', '4.6', '0.2', '0.0', '0.1', '1.3', '0.3', '2.5', '0.2', '2.1', '1.1', '4.2', '3.4', '2.5', '8.5', '4.8', '0.1', '0.2', '2.7', '3.4', '11.4', '0.3', '4.3', '0.9', '0.0', '5.1', '1.5', '1.8', '0.0', '5.5', '3.3', '0.2', '2.3', '0.2', '1.7', '5.5', '32.3', '1.9', '0.1', '0.1', '0.2', '2.9', '2.8', '2.0', '0.1', '1.4', '8.2', '4.3', '1.4', '0.1', '0.0', '1.6', '1.2', '0.0', '0.1', '0.3', '3.4', '0.2', '2.3', '12.7', '1.9', '1.8', '0.2', '0.1', '0.0', '1.7', '5.5', '0.6', '1.5', '4.8', '0.1', '2.7', '0.0', '3.6', '1.4', '0.1', '13.1', '0.3', '4.4', '7.8', '2.5', '7.0', '2.3', '0.1', '0.2', '3.0', '1.1', '1.5', '0.5', '0.1', '4.3', '1.3', '0.1', '0.2', '10.8', '1.8', '0.1', '4.8', '2.8', '2.3', '6.3', '0.3', '0.3', '4.8', '0.3', '1.7', '4.0', '0.1', '1.8', '3.0', '3.1', '3.0', '21.5', '9.7', '0.0', '3.1', '0.2', '2.7', '0.0', '4.5', '13.1', '0.2', '2.1', '0.0', '1.4', '0.1', '1.3', '1.4', '0.1', '0.1', '4.5', '3.4', '2.9', '0.1', '1.1', '11.2', '8.7', '5.1', '3.0', '3.2', '2.4', '0.0', '0.1', '0.0', '5.4', '6.6', '0.2', '2.7', '1.2', '4.0', '2.4', '0.0', '2.6', '8.6', '5.0', '1.8', '2.6', '2.7', '6.6', '2.8', '5.9', '0.1', '5.6', '2.7', '2.6', '14.3', '2.2', '3.4', '6.4', '2.2', '3.5', '0.2', '8.2', '0.4', '5.9', '1.5', '2.4', '5.3', '5.5', '3.7', '4.8', '2.4', '7.8', '3.3', '3.2', '3.1', '4.2', '6.8', '0.0', '6.2', '3.0', '3.4', '9.5', '0.9', '14.6', '1.8', '6.3', '0.4', '0.2', '3.7', '2.9', '0.0', '0.6', '2.6', '2.3', '0.2', '27.5', '0.2', '0.3', '2.3', '3.4', '6.3', '1.6', '5.9', '0.0', '1.2', '2.7', '3.0', '1.7', '0.1', '2.7', '2.0', '8.6', '1.7', '1.4', '0.0', '6.0', '2.4', '3.5', '8.1', '0.0', '0.1', '7.5', '4.1', '4.0', '4.7', '6.8', '3.8', '']\n",
            "final avg bleu score: 3.26\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}